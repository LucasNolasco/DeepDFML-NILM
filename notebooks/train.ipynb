{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Train\n","\n","Notebook for training the model.\n","\n","## Load data"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5915021,"status":"ok","timestamp":1636637657499,"user":{"displayName":"Lucas Nolasco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGLUXEYi3rzVzNyfm5u9Dk6d49ZQOjdyvVjN0F6g=s64","userId":"08809505737985133054"},"user_tz":180},"id":"Dt-KXd0x2uIM","outputId":"aae12f3e-44dc-400e-e214-2bc7ff10b238"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]},{"name":"stdout","output_type":"stream","text":["Sorted data not found, creating new file...\n","Loading 1\n"]},{"name":"stderr","output_type":"stream","text":["416it [00:49,  8.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(832, 16640, 1)\n","Loading 2\n"]},{"name":"stderr","output_type":"stream","text":["672it [03:27,  3.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(2688, 16640, 1)\n","Loading 3\n"]},{"name":"stderr","output_type":"stream","text":["528it [03:53,  2.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(3168, 16640, 1)\n","Loading 8\n"]},{"name":"stderr","output_type":"stream","text":["96it [01:05,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(1728, 16640, 1)\n","Data loaded\n","Data sorted\n","Data stored\n","(7575, 16640, 1)\n","(841, 16640, 1)\n"]}],"source":["from sklearn.preprocessing import MaxAbsScaler\n","from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np\n","import os\n","import pickle\n","\n","import sys\n","sys.path.append(\"../src\")\n","\n","from DataHandler import DataHandler\n","from ModelHandler import ModelHandler\n","from PostProcessing import PostProcessing\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"," \n","configs = {\n","    \"N_GRIDS\": 5, \n","    \"SIGNAL_BASE_LENGTH\": 12800, \n","    \"N_CLASS\": 26, \n","    \"USE_NO_LOAD\": False, \n","    \"USE_HAND_AUGMENTATION\": False, \n","    \"MARGIN_RATIO\": 0.15, \n","    \"DATASET_PATH\": \"../Synthetic_Full_iHall.hdf5\",\n","    \"TRAIN_SIZE\": 0.9,\n","    \"FOLDER_PATH\": \"../tmp/Scattering/002/\", \n","    \"FOLDER_DATA_PATH\": \"../tmp/Scattering/002/\", \n","    \"N_EPOCHS_TRAINING\": 5000,\n","    \"INITIAL_EPOCH\": 0,\n","    \"TOTAL_MAX_EPOCHS\": 5000,\n","    \"SNRdb\": None # Noise level on db\n","}\n","\n","def freeze(model, task_name='classification'):\n","    for layer in model.layers:\n","        if task_name in layer.name:\n","            layer.trainable = True\n","        else:\n","            layer.trainable = False\n","\n","    for layer in model.layers:\n","        print(layer.name, layer.trainable)\n","\n","    return model\n","\n","def calculating_class_weights(y_true):\n","    '''\n","        Source: https://stackoverflow.com/questions/48485870/multi-label-classification-with-class-weights-in-keras\n","    '''\n","    from sklearn.utils.class_weight import compute_class_weight\n","    number_dim = np.shape(y_true)[1]\n","    weights = np.empty([number_dim, 2])\n","    for i in range(number_dim):\n","        weights[i] = compute_class_weight(class_weight='balanced', classes=[0.,1.], y=y_true[:, i])\n","    return weights\n","\n","ngrids = configs[\"N_GRIDS\"]\n","signalBaseLength = configs[\"SIGNAL_BASE_LENGTH\"]\n","trainSize = configs[\"TRAIN_SIZE\"]\n","folderDataPath = configs[\"FOLDER_DATA_PATH\"]\n"," \n","dataHandler = DataHandler(configs)\n","\n","# Se não tiver os dados no formato necessário já organizados, faz a organização\n","if not os.path.isfile(folderDataPath + \"data.p\"):\n","    print(\"Sorted data not found, creating new file...\")\n","    x, ydet, yclass, ytype, ygroup = dataHandler.loadData(hand_augmentation=configs[\"USE_HAND_AUGMENTATION\"], SNR=configs[\"SNRdb\"])\n","    print(\"Data loaded\")\n","\n","    data_mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","    strat_classes = np.max(yclass, axis=1)\n","\n","    train_index, test_index = next(data_mskf.split(x, strat_classes))\n","\n","    y_train = {\n","        \"detection\": ydet[train_index], \n","        \"type\": ytype[train_index], \n","        \"classification\": yclass[train_index], \n","        \"group\": ygroup[train_index]\n","    }\n","    \n","    y_test = {\n","        \"detection\": ydet[test_index], \n","        \"type\": ytype[test_index], \n","        \"classification\": yclass[test_index], \n","        \"group\": ygroup[test_index]\n","    }\n","    \n","    dict_data = {\n","        \"x_train\": x[train_index], \n","        \"x_test\": x[test_index], \n","        \"y_train\": y_train, \n","        \"y_test\": y_test\n","    }\n","\n","    print(\"Data sorted\")\n","\n","    try:\n","        os.mkdir(folderDataPath)\n","    except:\n","        pass\n","\n","    pickle.dump(dict_data, open(folderDataPath + \"data.p\", \"wb\"))\n","    print(\"Data stored\")\n","else:\n","    dict_data = pickle.load(open(folderDataPath + \"data.p\", \"rb\"))\n","\n","print(dict_data[\"x_train\"].shape)\n","print(dict_data[\"x_test\"].shape)\n","\n","modelHandler = ModelHandler(configs)\n","postProcessing = PostProcessing(configs)\n"," \n","X_all = dict_data[\"x_train\"]\n","ydet_all = dict_data[\"y_train\"][\"detection\"]\n","ytype_all = dict_data[\"y_train\"][\"type\"]\n","yclass_all = dict_data[\"y_train\"][\"classification\"]"]},{"cell_type":"markdown","metadata":{},"source":["## Scattering\n","\n","Builds the scattering model"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 16640)]           0         \n","_________________________________________________________________\n","scattering1d (Scattering1D)  (None, 628, 17)           0         \n","_________________________________________________________________\n","lambda (Lambda)              (None, 627, 17)           0         \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 627, 17)           0         \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 627)               0         \n","=================================================================\n","Total params: 0\n","Trainable params: 0\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Lambda, GlobalAveragePooling1D\n","from tensorflow.keras.models import Model\n","from kymatio.keras import Scattering1D\n","\n","def buildBaseScattering(input_shape):\n","    '''\n","        Source: https://github.com/kymatio/kymatio/blob/master/examples/1d/classif_keras.py\n","    '''\n","    log_eps = 1e-6\n","\n","    input = Input(shape=(input_shape,))\n","    x = Scattering1D(10, 14)(input) # Changed J from 8 to 10 -> Results in a flatten with 544 parameters (the original with convolutions has 520)\n","    ###############################################################################\n","    # Since it does not carry useful information, we remove the zeroth-order\n","    # scattering coefficients, which are always placed in the first channel of\n","    # the scattering transform.\n","\n","    x = Lambda(lambda x: x[..., 1:, :])(x)\n","\n","    # To increase discriminability, we take the logarithm of the scattering\n","    # coefficients (after adding a small constant to make sure nothing blows up\n","    # when scattering coefficients are close to zero). This is known as the\n","    # log-scattering transform.\n","\n","    x = Lambda(lambda x: tf.math.log(tf.abs(x) + log_eps))(x)\n","\n","    ###############################################################################\n","    # We then average along the last dimension (time) to get a time-shift\n","    # invariant representation.\n","\n","    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n","\n","    model = Model(inputs = input, outputs=x)\n","\n","    return model\n","\n","if not os.path.isfile(configs[\"FOLDER_PATH\"] + 'scattering_model.h5'):\n","    scattering_extract = buildBaseScattering(X_all.shape[1])\n","    scattering_extract.save(configs[\"FOLDER_PATH\"] + 'scattering_model.h5')\n","else:\n","    scattering_extract = modelHandler.loadModel(configs[\"FOLDER_PATH\"] + 'scattering_model.h5')\n","\n","scattering_extract.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## New Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fold = 0\n","mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","strat_classes = np.max(yclass_all, axis=1)\n","print(strat_classes.shape)\n","\n","for train_index, validation_index in mskf.split(X_all, strat_classes):\n","    fold += 1\n","\n","    print(f\"---------- FOLD {fold} -------------\")\n","\n","    scaler = MaxAbsScaler()\n","    scaler.fit(np.squeeze(X_all[train_index], axis=2))\n","    x_train = np.expand_dims(scaler.transform(np.squeeze(X_all[train_index], axis=2)), axis=2)\n","    x_validation = np.expand_dims(scaler.transform(np.squeeze(X_all[validation_index], axis=2)), axis=2)\n","    \n","    x_train = scattering_extract.predict(x_train)\n","    x_validation = scattering_extract.predict(x_validation)\n","\n","    print(x_train.shape)\n","\n","    y_train, y_validation = {}, {}\n","    y_train[\"detection\"] = ydet_all[train_index]\n","    y_validation[\"detection\"] = ydet_all[validation_index]\n","    y_train[\"type\"] = ytype_all[train_index]\n","    y_validation[\"type\"] = ytype_all[validation_index]\n","    y_train[\"classification\"] = yclass_all[train_index]\n","    y_validation[\"classification\"] = yclass_all[validation_index]\n","\n","    yclass_weights = calculating_class_weights(np.max(y_train[\"classification\"], axis=1))\n","\n","    print(yclass_weights)\n","    \n","    folderPath = configs[\"FOLDER_PATH\"] + str(fold) + \"/\"\n","    try:\n","        os.mkdir(folderPath)\n","    except:\n","        pass\n","\n","    np.save(folderPath + \"train_index.npy\", train_index)\n","    np.save(folderPath + \"validation_index.npy\", validation_index)\n","    \n","    tensorboard_callback = TensorBoard(log_dir='./' + configs[\"FOLDER_PATH\"] + '/logs')\n","\n","    if configs[\"INITIAL_EPOCH\"] > 0:\n","        model = ModelHandler.loadModel(folderPath + 'model_{0}.h5'.format(configs[\"INITIAL_EPOCH\"]))\n","    else:\n","        model = modelHandler.buildScatteringOutput(input_shape=x_train.shape[1])\n"," \n","    model.summary()\n"," \n","    fileEpoch = configs[\"INITIAL_EPOCH\"]\n","    while fileEpoch < configs[\"TOTAL_MAX_EPOCHS\"]:\n","        fileEpoch += configs[\"N_EPOCHS_TRAINING\"]      \n","\n","        if not os.path.isfile(folderPath + 'model.h5'):\n","            for subtask in ['type', 'detection', 'classification']:\n","                print(f\"FOLD {fold}: Training {subtask}\")\n","                \n","                freeze(model, task_name=subtask)\n","                model.compile(optimizer = Adam(), \\\n","                              loss = [ModelHandler.sumSquaredError, \"categorical_crossentropy\", ModelHandler.get_bce_weighted_loss(yclass_weights)], \\\n","                              metrics=[['mean_squared_error'], ['categorical_accuracy'], ['binary_accuracy']])\n","                \n","                early_stopping_callback = EarlyStopping(monitor=f\"val_{subtask}_loss\", patience=50, verbose=True, restore_best_weights=True)\n","                hist_opt = model.fit(x=x_train, y=[y_train[\"detection\"], y_train[\"type\"], y_train[\"classification\"]], \\\n","                                    validation_data=(x_validation, [y_validation[\"detection\"], y_validation[\"type\"], y_validation[\"classification\"]]), \\\n","                                    epochs=configs[\"N_EPOCHS_TRAINING\"], verbose=2, callbacks=[early_stopping_callback, tensorboard_callback], batch_size=32)\n","            \n","            model.save(folderPath + 'model.h5')\n","  \n","    del model, y_validation, y_train, x_validation, x_train"]},{"cell_type":"markdown","metadata":{},"source":["## Old Train"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(18723, 26)\n","---------- FOLD 1 -------------\n","[[ 0.54978454  5.52163934]\n"," [ 0.55071942  5.42907801]\n"," [ 0.50298668 84.205     ]\n"," [ 0.56039531  4.63939394]\n"," [ 0.57568196  3.8032972 ]\n"," [ 0.50388965 64.77307692]\n"," [ 0.51866338 13.89521452]\n"," [ 0.61217739  2.72861309]\n"," [ 0.54788861  5.72044837]\n"," [ 0.50543217 46.52209945]\n"," [ 0.51160459 22.04319372]\n"," [ 0.55639619  4.93292326]\n"," [ 0.66946255  1.97525217]\n"," [ 0.57560325  3.80673599]\n"," [ 0.50695364 36.45238095]\n"," [ 0.57678608  3.75579839]\n"," [ 0.56949141  4.09756691]\n"," [ 0.51735684 14.90353982]\n"," [ 0.52661038  9.89482961]\n"," [ 0.51764308 14.66986063]\n"," [ 0.52740198  9.62342857]\n"," [ 0.53065919  8.65416238]\n"," [ 0.53473678  7.69698355]\n"," [ 0.52392359 10.94993498]\n"," [ 0.53688472  7.27787381]\n"," [ 0.53324679  8.01952381]]\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 627)]        0                                            \n","__________________________________________________________________________________________________\n","detection_dense_0 (Dense)       (None, 200)          125600      input_4[0][0]                    \n","__________________________________________________________________________________________________\n","classification_dense_0 (Dense)  (None, 300)          188400      input_4[0][0]                    \n","__________________________________________________________________________________________________\n","detection_leaky_0 (LeakyReLU)   (None, 200)          0           detection_dense_0[0][0]          \n","__________________________________________________________________________________________________\n","classification_leaky_0 (LeakyRe (None, 300)          0           classification_dense_0[0][0]     \n","__________________________________________________________________________________________________\n","detection_dropout (Dropout)     (None, 200)          0           detection_leaky_0[0][0]          \n","__________________________________________________________________________________________________\n","type_dense_0 (Dense)            (None, 10)           6280        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","classification_dropout (Dropout (None, 300)          0           classification_leaky_0[0][0]     \n","__________________________________________________________________________________________________\n","detection_dense_1 (Dense)       (None, 20)           4020        detection_dropout[0][0]          \n","__________________________________________________________________________________________________\n","type_leaky_0 (LeakyReLU)        (None, 10)           0           type_dense_0[0][0]               \n","__________________________________________________________________________________________________\n","classification_dense_1 (Dense)  (None, 300)          90300       classification_dropout[0][0]     \n","__________________________________________________________________________________________________\n","detection_leaky_1 (LeakyReLU)   (None, 20)           0           detection_dense_1[0][0]          \n","__________________________________________________________________________________________________\n","type_dense_1 (Dense)            (None, 15)           165         type_leaky_0[0][0]               \n","__________________________________________________________________________________________________\n","classification_leaky_1 (LeakyRe (None, 300)          0           classification_dense_1[0][0]     \n","__________________________________________________________________________________________________\n","detection_dense_2 (Dense)       (None, 5)            105         detection_leaky_1[0][0]          \n","__________________________________________________________________________________________________\n","type_reshape (Reshape)          (None, 5, 3)         0           type_dense_1[0][0]               \n","__________________________________________________________________________________________________\n","classification_dense_2 (Dense)  (None, 130)          39130       classification_leaky_1[0][0]     \n","__________________________________________________________________________________________________\n","detection (Reshape)             (None, 5, 1)         0           detection_dense_2[0][0]          \n","__________________________________________________________________________________________________\n","type (Softmax)                  (None, 5, 3)         0           type_reshape[0][0]               \n","__________________________________________________________________________________________________\n","classification (Reshape)        (None, 5, 26)        0           classification_dense_2[0][0]     \n","==================================================================================================\n","Total params: 454,000\n","Trainable params: 454,000\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/5000\n","527/527 - 11s - loss: 1.1275 - detection_loss: 0.0268 - type_loss: 0.4262 - classification_loss: 0.6746 - detection_mean_squared_error: 0.3945 - type_categorical_accuracy: 0.9016 - classification_binary_accuracy: 0.6193 - val_loss: 1.0057 - val_detection_loss: 0.0283 - val_type_loss: 0.3530 - val_classification_loss: 0.6243 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.5569\n","Epoch 2/5000\n","527/527 - 4s - loss: 0.9274 - detection_loss: 0.0267 - type_loss: 0.3470 - classification_loss: 0.5537 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.6619 - val_loss: 0.9202 - val_detection_loss: 0.0283 - val_type_loss: 0.3609 - val_classification_loss: 0.5309 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7588\n","Epoch 3/5000\n","527/527 - 5s - loss: 0.8955 - detection_loss: 0.0267 - type_loss: 0.3432 - classification_loss: 0.5255 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.6747 - val_loss: 0.8600 - val_detection_loss: 0.0283 - val_type_loss: 0.3504 - val_classification_loss: 0.4813 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7167\n","Epoch 4/5000\n","527/527 - 4s - loss: 0.8802 - detection_loss: 0.0267 - type_loss: 0.3410 - classification_loss: 0.5125 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.6877 - val_loss: 0.8623 - val_detection_loss: 0.0283 - val_type_loss: 0.3532 - val_classification_loss: 0.4808 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.6689\n","Epoch 5/5000\n","527/527 - 4s - loss: 0.8615 - detection_loss: 0.0267 - type_loss: 0.3396 - classification_loss: 0.4951 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.7028 - val_loss: 0.8782 - val_detection_loss: 0.0283 - val_type_loss: 0.3549 - val_classification_loss: 0.4950 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.6791\n","Epoch 6/5000\n","527/527 - 4s - loss: 0.8283 - detection_loss: 0.0267 - type_loss: 0.3389 - classification_loss: 0.4626 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.7274 - val_loss: 0.8444 - val_detection_loss: 0.0283 - val_type_loss: 0.3422 - val_classification_loss: 0.4738 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7348\n","Epoch 7/5000\n","527/527 - 4s - loss: 0.8218 - detection_loss: 0.0267 - type_loss: 0.3370 - classification_loss: 0.4580 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9193 - classification_binary_accuracy: 0.7375 - val_loss: 0.8142 - val_detection_loss: 0.0283 - val_type_loss: 0.3419 - val_classification_loss: 0.4440 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7520\n","Epoch 8/5000\n","527/527 - 4s - loss: 0.8029 - detection_loss: 0.0267 - type_loss: 0.3336 - classification_loss: 0.4426 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.7510 - val_loss: 0.7729 - val_detection_loss: 0.0283 - val_type_loss: 0.3365 - val_classification_loss: 0.4081 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7657\n","Epoch 9/5000\n","527/527 - 4s - loss: 0.7897 - detection_loss: 0.0267 - type_loss: 0.3379 - classification_loss: 0.4251 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9192 - classification_binary_accuracy: 0.7636 - val_loss: 0.7382 - val_detection_loss: 0.0283 - val_type_loss: 0.3369 - val_classification_loss: 0.3730 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7806\n","Epoch 10/5000\n","527/527 - 4s - loss: 0.7672 - detection_loss: 0.0267 - type_loss: 0.3307 - classification_loss: 0.4098 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.7744 - val_loss: 0.7258 - val_detection_loss: 0.0283 - val_type_loss: 0.3355 - val_classification_loss: 0.3620 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.8068\n","Epoch 11/5000\n","527/527 - 4s - loss: 0.7559 - detection_loss: 0.0267 - type_loss: 0.3288 - classification_loss: 0.4003 - detection_mean_squared_error: 0.3944 - type_categorical_accuracy: 0.9194 - classification_binary_accuracy: 0.7795 - val_loss: 0.8144 - val_detection_loss: 0.0283 - val_type_loss: 0.3358 - val_classification_loss: 0.4502 - val_detection_mean_squared_error: 0.3939 - val_type_categorical_accuracy: 0.9167 - val_classification_binary_accuracy: 0.7914\n","Epoch 12/5000\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19560/2797645931.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m                           \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mModelHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msumSquaredError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_bce_weighted_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myclass_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                           metrics=[['mean_squared_error'], ['categorical_accuracy'], ['binary_accuracy']])\n\u001b[1;32m---> 61\u001b[1;33m             hist = model.fit(x=x_train, y=[y_train[\"detection\"], y_train[\"type\"], y_train[\"classification\"]], \\\n\u001b[0m\u001b[0;32m     62\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"detection\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"classification\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                              epochs=configs[\"N_EPOCHS_TRAINING\"], verbose=2, callbacks=[early_stopping_callback, tensorboard_callback], batch_size=32)\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mf:\\TCC\\programas\\nilm_venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fold = 0\n","mskf = MultilabelStratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","strat_classes = np.max(yclass_all, axis=1)\n","print(strat_classes.shape)\n","\n","for train_index, validation_index in mskf.split(X_all, strat_classes):\n","    fold += 1\n","\n","    print(f\"---------- FOLD {fold} -------------\")\n","\n","    if fold != 1:\n","        scaler = MaxAbsScaler()\n","        scaler.fit(np.squeeze(X_all[train_index], axis=2))\n","        x_train = np.expand_dims(scaler.transform(np.squeeze(X_all[train_index], axis=2)), axis=2)\n","        x_validation = np.expand_dims(scaler.transform(np.squeeze(X_all[validation_index], axis=2)), axis=2)\n","        \n","        x_train = scattering_extract.predict(x_train)\n","        x_validation = scattering_extract.predict(x_validation)\n","\n","    y_train, y_validation = {}, {}\n","    y_train[\"detection\"] = ydet_all[train_index]\n","    y_validation[\"detection\"] = ydet_all[validation_index]\n","    y_train[\"type\"] = ytype_all[train_index]\n","    y_validation[\"type\"] = ytype_all[validation_index]\n","    y_train[\"classification\"] = yclass_all[train_index]\n","    y_validation[\"classification\"] = yclass_all[validation_index]\n","\n","    yclass_weights = calculating_class_weights(np.max(y_train[\"classification\"], axis=1))\n","    print(yclass_weights)\n","    \n","    folderPath = configs[\"FOLDER_PATH\"] + str(fold) + \"/\"\n","    try:\n","        os.mkdir(folderPath)\n","    except:\n","        pass\n","\n","    np.save(folderPath + \"train_index.npy\", train_index)\n","    np.save(folderPath + \"validation_index.npy\", validation_index)\n","    \n","    tensorboard_callback = TensorBoard(log_dir='./' + configs[\"FOLDER_PATH\"] + '/logs')\n","    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50, verbose=True, restore_best_weights=True)\n","    classification_early_stopping_callback = EarlyStopping(monitor='val_classification_loss', patience=50, verbose=True, restore_best_weights=True)\n","    detection_early_stopping_callback = EarlyStopping(monitor='val_detection_loss', patience=50, verbose=True, restore_best_weights=True)\n","    type_early_stopping_callback = EarlyStopping(monitor='val_type_loss', patience=50, verbose=True, restore_best_weights=True)\n","\n","    if configs[\"INITIAL_EPOCH\"] > 0:\n","        model = ModelHandler.loadModel(folderPath + 'model_{0}.h5'.format(configs[\"INITIAL_EPOCH\"]))\n","    else:\n","        model = modelHandler.buildScatteringOutput(input_shape=x_train.shape[1])\n"," \n","    model.summary()\n"," \n","    fileEpoch = configs[\"INITIAL_EPOCH\"]\n","    while fileEpoch < configs[\"TOTAL_MAX_EPOCHS\"]:\n","        fileEpoch += configs[\"N_EPOCHS_TRAINING\"]\n","\n","        if not os.path.isfile(folderPath + 'model.h5'):\n","            model.compile(optimizer = Adam(), \\\n","                          loss = [ModelHandler.sumSquaredError, \"categorical_crossentropy\", ModelHandler.get_bce_weighted_loss(yclass_weights)], \\\n","                          metrics=[['mean_squared_error'], ['categorical_accuracy'], ['binary_accuracy']])\n","            hist = model.fit(x=x_train, y=[y_train[\"detection\"], y_train[\"type\"], y_train[\"classification\"]], \\\n","                             validation_data=(x_validation, [y_validation[\"detection\"], y_validation[\"type\"], y_validation[\"classification\"]]), \\\n","                             epochs=configs[\"N_EPOCHS_TRAINING\"], verbose=2, callbacks=[early_stopping_callback, tensorboard_callback], batch_size=32)\n","\n","            model.save(folderPath + 'model.h5')\n","        else: # If this model already exists, loads it\n","            model = ModelHandler.loadModel(folderPath + \"model.h5\")        \n","\n","        if not os.path.isfile(folderPath + 'model_class_opt.h5'):\n","            print(f\"FOLD {fold}: CLASSIFICATION FINE TUNNING PHASE\")\n","            freeze(model)\n","            model.compile(optimizer = Adam(learning_rate=0.00001), \\\n","                          loss = [ModelHandler.sumSquaredError, \"categorical_crossentropy\", ModelHandler.get_bce_weighted_loss(yclass_weights)], \\\n","                          metrics=[['mean_squared_error'], ['categorical_accuracy'], ['binary_accuracy']])\n","\n","            hist_opt = model.fit(x=x_train, y=[y_train[\"detection\"], y_train[\"type\"], y_train[\"classification\"]], \\\n","                                 validation_data=(x_validation, [y_validation[\"detection\"], y_validation[\"type\"], y_validation[\"classification\"]]), \\\n","                                 epochs=configs[\"N_EPOCHS_TRAINING\"], verbose=2, callbacks=[classification_early_stopping_callback, tensorboard_callback], batch_size=32)\n","          \n","            model.save(folderPath + 'model_class_opt.h5')\n","  \n","    del model, y_validation, y_train, x_validation, x_train"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPj1HURYkxpzYDjwSUkgEzm","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1xNa0oegIS-FXUQsc8nRerpaHb11oyys_","name":"nilm_full_kfold_train.ipynb","provenance":[{"file_id":"1oTHch2gO6f5wcaeeiFViut4gA8PsEoTo","timestamp":1626122781670}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":0}

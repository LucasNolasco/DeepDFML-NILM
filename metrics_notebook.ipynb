{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, multilabel_confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from ModelHandler import ModelHandler\n",
    "import pickle\n",
    "import h5py\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score     \n",
    "\n",
    "configs = {\n",
    "    \"N_GRIDS\": 5, \n",
    "    \"SIGNAL_BASE_LENGTH\": 12800, \n",
    "    \"N_CLASS\": 26, \n",
    "    \"USE_NO_LOAD\": False, \n",
    "    \"AUGMENTATION_RATIO\": 5, \n",
    "    \"MARGIN_RATIO\": 0.15, \n",
    "    \"DATASET_PATH\": \"Synthetic_Full_iHall.hdf5\",\n",
    "    \"TRAIN_SIZE\": 0.8,\n",
    "    \"FOLDER_PATH\": \"tmp/new_aug/\", \n",
    "    \"FOLDER_DATA_PATH\": \"tmp/new_aug/\", \n",
    "    \"N_EPOCHS_TRAINING\": 250,\n",
    "    \"INITIAL_EPOCH\": 0,\n",
    "    \"TOTAL_MAX_EPOCHS\": 250,\n",
    "    \"SNRdb\": None # Nível de ruído em db\n",
    "}\n",
    "\n",
    "\n",
    "folderPath = \"tmp/new_aug_correct/\"\n",
    "folderDataPath = \"tmp/new_aug_correct/\"\n",
    "signalBaseLength = 12800\n",
    "trainSize = 0.8\n",
    "ngrids = 5\n",
    "\n",
    "FOLD = False\n",
    "\n",
    "dict_data = pickle.load(open(folderDataPath + \"sorted_aug_data_\" + str(ngrids) + \"_\" + str(signalBaseLength) + \".p\", \"rb\")) # Load data\n",
    "x_train = dict_data[\"x_train\"]\n",
    "x_test = dict_data[\"x_test\"]\n",
    "y_train = dict_data[\"y_train\"]\n",
    "y_test = dict_data[\"y_test\"]\n",
    "\n",
    "datasetPath = \"Synthetic_Full_iHall.hdf5\"\n",
    "\n",
    "all_labels = []\n",
    "\n",
    "arq = h5py.File(datasetPath, \"r\")\n",
    "loads_list = [\"1\", \"2\", \"3\", \"8\"]\n",
    "for load_qtd in loads_list:\n",
    "    labels = arq[load_qtd][\"labels\"]  \n",
    "    events = arq[load_qtd][\"events\"]    \n",
    "    for waveform_labels, event in zip(labels, events):\n",
    "        event_index = np.argwhere(event != 0)\n",
    "        # events = event[event_index]\n",
    "        for label, ev in zip(waveform_labels, event_index):\n",
    "            all_labels.append(event[ev][0] * (label + 1))\n",
    "\n",
    "copia_all_labels = all_labels.copy()\n",
    "for i in range(int((len(y_test[\"classification\"]) + len(y_train[\"classification\"]))/len(copia_all_labels)) - 1):\n",
    "    for label in copia_all_labels:\n",
    "        all_labels.append(label)\n",
    "\n",
    "labels_train, labels_test = train_test_split(all_labels, train_size=int(trainSize * len(all_labels)), random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/lucasnolasco/SharedDocuments/projeto_yolo_nilm/programas/PostProcessing.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(events)\n",
      "Total time: 81.34003296001538, Average Time: 0.04182006835990508\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([3803, 1]) list([0, 0.99956423])\n",
      "  list([[12, 0.9682094], [19, 1.0], [21, 0.99824065]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([7163, 1]) list([1, 0.55322355])\n",
      "  list([[3, 0.999881], [6, 0.99991786], [7, 0.96344185], [12, 0.9662976], [18, 1.0]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([2930, 1]) list([0, 0.98778373])\n",
      "  list([[12, 0.94346106], [19, 1.0], [21, 0.9966988]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[[5273 1]\n",
      "  [0 0.85353154]\n",
      "  [list([12, 0.95971775]) list([16, 0.998569])]]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([12379, 1]) list([0, 0.8966135])\n",
      "  list([[3, 1.0], [12, 0.9999906], [18, 1.0]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[[10353 1]\n",
      "  [0 0.92640984]\n",
      "  [list([3, 0.99989957]) list([12, 0.9999826])]]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([4774, 1]) list([0, 0.9942848])\n",
      "  list([[12, 0.9552834], [19, 0.9999999], [21, 0.99870056]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([3461, 1]) list([0, 0.9999963])\n",
      "  list([[3, 0.99154603], [6, 0.99997896], [7, 0.7638521], [12, 0.8030859], [18, 1.0]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[[13818 1]\n",
      "  [0 0.9953921]\n",
      "  [list([4, 0.9348458]) list([17, 0.9999889])]]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[[8496 1]\n",
      "  [1 0.9861136]\n",
      "  [list([12, 0.920021]) list([16, 0.999834])]]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([13291, 1]) list([0, 0.92706686]) list([[13, 0.99999225]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([4803, 1]) list([0, 0.9737916])\n",
      "  list([[7, 0.9196048], [10, 0.80879843], [13, 0.5138083], [16, 0.99996]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([11243, 1]) list([0, 0.7208831])\n",
      "  list([[4, 0.99080217], [17, 0.99999976], [18, 0.6539744]])]]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] [[list([3706, 1]) list([0, 0.5261069])\n",
      "  list([[3, 1.0], [6, 0.99999154], [12, 0.64966786], [15, 0.99854034], [16, 0.99994814]])]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-abcc18a05ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpcMetric_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdMetric_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostProcessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcMetric_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdMetric_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SharedDocuments/projeto_yolo_nilm/programas/PostProcessing.py\u001b[0m in \u001b[0;36mcheckModel\u001b[0;34m(self, model, x, y, load_type, general_qtd, print_error)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mPCmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundTruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneral_qtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mDmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverageDistanceMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundTruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneral_qtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LIT-SYN-All PCmetric: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPCmetric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SharedDocuments/projeto_yolo_nilm/programas/PostProcessing.py\u001b[0m in \u001b[0;36maverageDistanceMetric\u001b[0;34m(self, groundTruth, predicted, general_acquisition_type, target)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mgt_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_events\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgt_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 10 semicycles tolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0mtotal_correct_on\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from PostProcessing import PostProcessing\n",
    "from DataHandler import DataHandler\n",
    "\n",
    "postProcessing = PostProcessing(configs=configs)\n",
    "dataHandler = DataHandler(configs=configs)\n",
    "bestModel = ModelHandler.loadModel(folderPath + \"multiple_loads_multipleOutputs_12800_250.h5\", type_weights=None) # Load model\n",
    "\n",
    "group_distribution = {\n",
    "    \"1\": 1094,\n",
    "    \"2\": 3362,\n",
    "    \"3\": 3443,\n",
    "    \"8\": 1823\n",
    "}\n",
    "\n",
    "pcMetric_fold, dMetric_fold = postProcessing.checkModel(bestModel, x_test, y_test, print_error=False)\n",
    "print(pcMetric_fold, dMetric_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FOLD == False:\n",
    "    threshold = 0.5\n",
    "    final_prediction = []\n",
    "    final_prediction_with_detection = []\n",
    "    final_groundTruth = []\n",
    "\n",
    "    bestModel = ModelHandler.loadModel(folderPath + \"best_model.h5\", type_weights=None) # Load model\n",
    "    for xi, yclass, ytype in zip(x_test, y_test[\"classification\"], y_test[\"type\"]):\n",
    "        pred = bestModel.predict(np.expand_dims(xi, axis=0))\n",
    "        prediction = np.max(pred[2][0],axis=0) # > threshold\n",
    "        groundTruth = np.max(yclass,axis=0) # > threshold\n",
    "\n",
    "        det = np.array([np.argmax(i) for i in ytype])\n",
    "        prediction_with_detection = np.max(pred[2][0],axis=0) > 2 # Gambiarra\n",
    "        if (det != 2).any():\n",
    "            prediction_with_detection = np.max(pred[2][0],axis=0) # > threshold\n",
    "\n",
    "        final_prediction.append(prediction)\n",
    "        final_groundTruth.append(groundTruth)\n",
    "        final_prediction_with_detection.append(prediction_with_detection)\n",
    "    \n",
    "    final_groundTruth = np.array(final_groundTruth)\n",
    "    final_prediction = np.array(final_prediction)\n",
    "    final_prediction_with_detection = np.array(final_prediction_with_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9352058967328291"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score   \n",
    "\n",
    "threshold = 0.5\n",
    "f1_score(final_groundTruth > threshold, final_prediction > threshold, average='macro')\n",
    "\n",
    "# train: 98,53% (0.9852785999750767 - F1 Macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9273809940497558"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "correct = np.zeros((26, 1))\n",
    "total = np.zeros((26, 1))\n",
    "\n",
    "threshold = 0.5\n",
    "for ytrue, ypred in zip(final_groundTruth, final_prediction):\n",
    "    correct[np.bitwise_and((ytrue > threshold), (ypred > threshold))] += 1\n",
    "    total[ytrue > threshold] += 1\n",
    "\n",
    "np.average(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc total: 0.03395798747846221, Acc on: 0.027627572503155458, Acc off: 0.04152930059182529\n"
     ]
    }
   ],
   "source": [
    "if FOLD == False:\n",
    "    correct_on = np.zeros((26,1))\n",
    "    total_on = np.zeros((26,1))\n",
    "    correct_off = np.zeros((26,1))\n",
    "    total_off = np.zeros((26,1))\n",
    "\n",
    "    for ytrue, ypred in zip(labels_test, final_prediction):\n",
    "        if ytrue > 0:\n",
    "            ytrue = ytrue - 1\n",
    "            total_on[ytrue] += 1\n",
    "            if ypred[ytrue] == 1:\n",
    "                correct_on[ytrue] += 1\n",
    "        elif ytrue < 0:\n",
    "            ytrue = -1 * ytrue - 1 # Multiplica por -1 para voltar a ser positivo e subtrai 1 para voltar a começar do índice 0\n",
    "            total_off[ytrue] += 1\n",
    "            if ypred[ytrue] == 1:\n",
    "                correct_off[ytrue] += 1\n",
    "\n",
    "    acc_on = np.average(correct_on/total_on) % 100\n",
    "    acc_off = np.average(correct_off/total_off) % 100\n",
    "    acc = np.average((correct_on + correct_off)/(total_on + total_off)) % 100\n",
    "    print(f\"Acc total: {acc}, Acc on: {acc_on}, Acc off: {acc_off}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 2/10 [09:25<37:26, 280.80s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if FOLD == True:\n",
    "    X_all = np.vstack((x_train, x_test))\n",
    "    ydet_all = np.vstack((y_train[\"detection\"], y_test[\"detection\"]))\n",
    "    ytype_all = np.vstack((y_train[\"type\"], y_test[\"type\"]))\n",
    "    yclass_all = np.vstack((y_train[\"classification\"], y_test[\"classification\"]))\n",
    "    all_labels = np.vstack((labels_train, labels_test))\n",
    "\n",
    "    final_acc_on, final_acc_off, final_acc = [], [], []\n",
    "    y = {}\n",
    "    for fold in tqdm(range(1, 11)):\n",
    "        foldFolderPath = folderPath + str(fold) + \"/\"\n",
    "        \n",
    "        train_index = np.load(foldFolderPath + \"train_index.npy\")\n",
    "        test_index = np.load(foldFolderPath + \"test_index.npy\")\n",
    "\n",
    "        bestModel = ModelHandler.loadModel(foldFolderPath + \"best_model.h5\", type_weights=None) # Load model\n",
    "\n",
    "        x_train = X_all[train_index]\n",
    "        x_test = X_all[test_index]\n",
    "        y_train[\"detection\"] = ydet_all[train_index]\n",
    "        y_test[\"detection\"] = ydet_all[test_index]\n",
    "        y_train[\"type\"] = ytype_all[train_index]\n",
    "        y_test[\"type\"] = ytype_all[test_index]\n",
    "        y_train[\"classification\"] = yclass_all[train_index]\n",
    "        y_test[\"classification\"] = yclass_all[test_index]\n",
    "\n",
    "        threshold = 0.5\n",
    "        final_prediction = []\n",
    "        final_prediction_with_detection = []\n",
    "        final_groundTruth = []\n",
    "        for xi, yclass, ytype in zip(x_test, y_test[\"classification\"], y_test[\"type\"]):\n",
    "            pred = bestModel.predict(np.expand_dims(xi, axis=0))\n",
    "            prediction = np.max(pred[2][0],axis=0)\n",
    "            groundTruth = np.max(yclass,axis=0)\n",
    "\n",
    "            det = np.array([np.argmax(i) for i in ytype])\n",
    "            prediction_with_detection = np.max(pred[2][0],axis=0) > 2 # Gambiarra\n",
    "            if (det != 2).any():\n",
    "                prediction_with_detection = np.max(pred[2][0],axis=0)\n",
    "\n",
    "            final_prediction.append(prediction)\n",
    "            final_groundTruth.append(groundTruth) \n",
    "            final_prediction_with_detection.append(prediction_with_detection)\n",
    "\n",
    "            del xi, yclass, ytype\n",
    "\n",
    "        y[fold] = {}\n",
    "        y[fold][\"true\"] = final_groundTruth.copy()\n",
    "        y[fold][\"pred\"] = final_prediction.copy()\n",
    "        y[fold][\"pred_with_detection\"] = final_prediction_with_detection.copy()\n",
    "\n",
    "        # print(f\"Predicted fold {fold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold: 1, Acc total: 96.19179349548342, Acc on: 92.54188709381307, Acc off: 97.5274383166575\n",
      "1303.0 1222.0\n",
      "Fold: 2, Acc total: 95.65102289155053, Acc on: 94.03519850479867, Acc off: 98.40275959687536\n",
      "1273.0 1252.0\n",
      "Fold: 3, Acc total: 95.3075428706147, Acc on: 93.1430313165447, Acc off: 97.41903864963594\n",
      "1246.0 1279.0\n",
      "Fold: 4, Acc total: 96.61971681945396, Acc on: 93.20210057918959, Acc off: 97.74236645839497\n",
      "1238.0 1287.0\n",
      "Fold: 5, Acc total: 96.85212387826562, Acc on: 96.51611396812046, Acc off: 97.19659215930764\n",
      "1262.0 1263.0\n",
      "Fold: 6, Acc total: 96.69528756713763, Acc on: 95.8988807370545, Acc off: 97.48798114609592\n",
      "1276.0 1249.0\n",
      "Fold: 7, Acc total: 95.70459625217663, Acc on: 94.47511607902067, Acc off: 96.71021932396536\n",
      "1265.0 1260.0\n",
      "Fold: 8, Acc total: 94.37035616309531, Acc on: 93.28365350513383, Acc off: 96.54961562950955\n",
      "1286.0 1239.0\n",
      "Fold: 9, Acc total: 97.2599338441672, Acc on: 96.85725475390774, Acc off: 98.03606136041445\n",
      "1240.0 1284.0\n",
      "Fold: 10, Acc total: 95.2306783082388, Acc on: 90.79295691641688, Acc off: 98.25727348158861\n",
      "1235.0 1289.0\n",
      "Average - Acc total: 95.98830520901836, Acc on: 94.07461934540001, Acc off: 97.53293461224453\n"
     ]
    }
   ],
   "source": [
    "if FOLD == True:\n",
    "    all_labels = np.vstack((labels_train, labels_test))\n",
    "\n",
    "    # acumulative_acc_on, acumulative_acc_off, acumulative_total_on, acumulative_total_off = [], [], [], []\n",
    "\n",
    "    final_acc_on, final_acc_off, final_acc = [], [], []\n",
    "    for fold in range(1, 11):\n",
    "        correct_on = np.zeros((26,1))\n",
    "        total_on = np.zeros((26,1))\n",
    "        correct_off = np.zeros((26,1))\n",
    "        total_off = np.zeros((26,1))\n",
    "\n",
    "        train_index = np.load(folderPath + str(fold) + \"/train_index.npy\")\n",
    "        test_index = np.load(folderPath + str(fold) + \"/test_index.npy\")\n",
    "\n",
    "        labels_train = all_labels[train_index]\n",
    "        labels_test = all_labels[test_index]\n",
    "\n",
    "        for ytrue, ypred in zip(labels_test, y[fold][\"pred\"]):\n",
    "            if ytrue > 0:\n",
    "                ytrue = ytrue - 1\n",
    "                total_on[ytrue] += 1\n",
    "                if ypred[ytrue] == 1:\n",
    "                    correct_on[ytrue] += 1\n",
    "            elif ytrue < 0:\n",
    "                ytrue = -1 * ytrue - 1 # Multiplica por -1 para voltar a ser positivo e subtrai 1 para voltar a começar do índice 0\n",
    "                total_off[ytrue] += 1\n",
    "                if ypred[ytrue] == 1:\n",
    "                    correct_off[ytrue] += 1\n",
    "            else:\n",
    "                print(ytrue)\n",
    "\n",
    "        acc_on = np.average(np.nan_to_num(correct_on/total_on, nan=0)) * 100\n",
    "        acc_off = np.average(np.nan_to_num(correct_off/total_off, nan=0)) * 100\n",
    "        acc = np.average(np.nan_to_num((correct_on + correct_off)/(total_on + total_off), nan=0)) * 100\n",
    "        print(f\"Fold: {fold}, Acc total: {acc}, Acc on: {acc_on}, Acc off: {acc_off}\")\n",
    "        print(np.sum(total_on), np.sum(total_off))\n",
    "\n",
    "        final_acc_on.append(acc_on)\n",
    "        final_acc_off.append(acc_off)\n",
    "        final_acc.append(acc)\n",
    "\n",
    "        # acumulative_acc_on.append(correct_on)\n",
    "        # acumulative_acc_off.append(correct_off)\n",
    "        # acumulative_total_on.append(total_on)\n",
    "        # acumulative_total_off.append(total_off)\n",
    "\n",
    "    print(f\"Average - Acc total: {np.average(final_acc)}, Acc on: {np.average(final_acc_on)}, Acc off: {np.average(final_acc_off)}\")\n",
    "\n",
    "    # acumulative_acc_on = np.sum(acumulative_acc_on, axis=0)\n",
    "    # acumulative_acc_off = np.sum(acumulative_acc_off, axis=0)\n",
    "    # acumulative_total_on = np.sum(acumulative_total_on, axis=0)\n",
    "    # acumulative_total_off = np.sum(acumulative_total_off, axis=0)\n",
    "\n",
    "    # print(f\"Average - Acc total: {np.average((acumulative_acc_on + acumulative_acc_off)/(acumulative_total_on + acumulative_total_off))}, Acc on: {np.average(acumulative_acc_on/acumulative_total_on)}, Acc off: {np.average(acumulative_acc_off/acumulative_total_off)}\")"
   ]
  },
  {
   "source": [
    "### Cálculo da acurácia \n",
    "\n",
    "Acurácia a definição e considerando cada saída da rede de classificação como um classificador binário\n",
    "\n",
    "$$\n",
    "\\begin{gather*}\n",
    "Acc_i = \\frac{TP + TN}{TP + TN + FP + FN} \\\\ \\\\\n",
    "Acc = \\frac{1}{N} \\sum_{i = 1}^{N} Acc_i\n",
    "\\end{gather*}\n",
    "$$\n",
    "\n",
    "- Acc_i: Acurácia para a carga i"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 1, Acc on: 0.9949524765334435, Acc off: 0.9965693063074406, Acc total: 0.9957349581111957\n",
      "Fold 2, Acc on: 0.9961326968396882, Acc off: 0.997081592528877, Acc total: 0.9966031987814167\n",
      "Fold 3, Acc on: 0.9939190023459686, Acc off: 0.9953990497383773, Acc total: 0.9946686976389947\n",
      "Fold 4, Acc on: 0.9975767366720517, Acc off: 0.997698882314267, Acc total: 0.9976389946686977\n",
      "Fold 5, Acc on: 0.9960685115201756, Acc off: 0.9969852000730861, Acc total: 0.9965270373191164\n",
      "Fold 6, Acc on: 0.9967446346756692, Acc off: 0.9971669643407033, Acc total: 0.996953541507997\n",
      "Fold 7, Acc on: 0.99738522347218, Acc off: 0.9973443223443224, Acc total: 0.9973648134044174\n",
      "Fold 8, Acc on: 0.9961418830003589, Acc off: 0.9971440988390143, Acc total: 0.9966336633663366\n",
      "Fold 9, Acc on: 0.9950682382133995, Acc off: 0.9945482866043615, Acc total: 0.9948037303425578\n",
      "Fold 10, Acc on: 0.9955154157583309, Acc off: 0.9976427761532494, Acc total: 0.996601852980617\n",
      "Total, Acc on: 0.9959504819031265, Acc off: 0.9967580479243698, Acc total: 0.9963530488121346\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "all_labels = np.vstack((labels_train, labels_test))\n",
    "\n",
    "acc_on, acc_off, acc_total = [], [], []\n",
    "for fold in range(1, 11):\n",
    "    correct_on = np.zeros((26,1))\n",
    "    total_on = np.zeros((26,1))\n",
    "    correct_off = np.zeros((26,1))\n",
    "    total_off = np.zeros((26,1))\n",
    "\n",
    "    train_index = np.load(folderPath + str(fold) + \"/train_index.npy\")\n",
    "    test_index = np.load(folderPath + str(fold) + \"/test_index.npy\")\n",
    "\n",
    "    labels_train = all_labels[train_index]\n",
    "    labels_test = all_labels[test_index]\n",
    "\n",
    "    for label, ytrue, ypred in zip(labels_test, y[fold][\"true\"], y[fold][\"pred\"]):\n",
    "        if label > 0:\n",
    "            # correct_on[np.bitwise_and(ytrue > threshold, ypred > threshold)] += 1\n",
    "            # total_on[ytrue > threshold] += 1\n",
    "            # total_on[np.bitwise_or(ytrue > threshold, ypred > threshold)] += 1\n",
    "            correct_on[(ytrue > threshold) == (ypred > threshold)] += 1\n",
    "            total_on += 1\n",
    "        elif label < 0:\n",
    "            # correct_off[np.bitwise_and(ytrue > threshold, ypred > threshold)] += 1\n",
    "            # total_off[ytrue > threshold] += 1\n",
    "            # total_off[np.bitwise_or(ytrue > threshold, ypred > threshold)] += 1\n",
    "            correct_off[(ytrue > threshold) == (ypred > threshold)] += 1\n",
    "            total_off += 1\n",
    "        \n",
    "    acc_on.append(np.average(np.nan_to_num(correct_on/total_on)))\n",
    "    acc_off.append(np.average(np.nan_to_num(correct_off/total_off)))\n",
    "    acc_total.append(np.average(np.nan_to_num((correct_on + correct_off)/(total_on + total_off))))\n",
    "\n",
    "    print(f\"Fold {fold}, Acc on: {acc_on[-1]}, Acc off: {acc_off[-1]}, Acc total: {acc_total[-1]}\")\n",
    "\n",
    "print(f\"Total, Acc on: {np.average(acc_on)}, Acc off: {np.average(acc_off)}, Acc total: {np.average(acc_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold 1, Acc on: 0.9431281226120443, Acc off: 0.9870077802926042, Acc total: 0.9758275127936348\n",
      "Fold 2, Acc on: 0.9543069157601172, Acc off: 0.9930085296482326, Acc total: 0.9684629239937494\n",
      "Fold 3, Acc on: 0.9526084057536229, Acc off: 0.9862392079219131, Acc total: 0.9690908704370735\n",
      "Fold 4, Acc on: 0.9502807985347455, Acc off: 0.9889651665328318, Acc total: 0.9809545914084766\n",
      "Fold 5, Acc on: 0.9816589508098907, Acc off: 0.9825139185044682, Acc total: 0.9824282046641915\n",
      "Fold 6, Acc on: 0.9743425143263184, Acc off: 0.9890447656456492, Acc total: 0.981763816654446\n",
      "Fold 7, Acc on: 0.9613606732632907, Acc off: 0.9840428812431075, Acc total: 0.9723644291135973\n",
      "Fold 8, Acc on: 0.9533552515979224, Acc off: 0.985447421355359, Acc total: 0.9623539480934623\n",
      "Fold 9, Acc on: 0.9844494129346484, Acc off: 0.9892635081876955, Acc total: 0.9864418885754864\n",
      "Fold 10, Acc on: 0.9313551116986496, Acc off: 0.9921141804938952, Acc total: 0.9696432031934634\n",
      "Total, Acc on: 0.958684615729125, Acc off: 0.9877647359825754, Acc total: 0.9749331388927581\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "all_labels = np.vstack((labels_train, labels_test))\n",
    "\n",
    "acc_on, acc_off, acc_total = [], [], []\n",
    "for fold in range(1, 11):\n",
    "    correct_on = np.zeros((26,1))\n",
    "    total_on = np.zeros((26,1))\n",
    "    correct_off = np.zeros((26,1))\n",
    "    total_off = np.zeros((26,1))\n",
    "\n",
    "    train_index = np.load(folderPath + str(fold) + \"/train_index.npy\")\n",
    "    test_index = np.load(folderPath + str(fold) + \"/test_index.npy\")\n",
    "\n",
    "    labels_train = all_labels[train_index]\n",
    "    labels_test = all_labels[test_index]\n",
    "\n",
    "    for label, ytrue, ypred in zip(labels_test, y[fold][\"true\"], y[fold][\"pred\"]):\n",
    "        if label > 0:\n",
    "            correct_on[(ytrue > threshold) == (ypred > threshold)] += 1\n",
    "            total_on[ytrue > threshold] += 1\n",
    "        elif label < 0:\n",
    "            correct_off[np.bitwise_and(ytrue > threshold, ypred > threshold)] += 1\n",
    "            total_off[ytrue > threshold] += 1\n",
    "\n",
    "    # total_on = np.where(total_on == 0, correct_on, total_on)\n",
    "    # total_off = np.where(total_off == 0, correct_off, total_off)    \n",
    "    \n",
    "    acc_on.append(np.average(np.nan_to_num(correct_on/total_on)))\n",
    "    acc_off.append(np.average(np.nan_to_num(correct_off/total_off)))\n",
    "    acc_total.append(np.average(np.nan_to_num((correct_on + correct_off)/(total_on + total_off))))\n",
    "\n",
    "    print(f\"Fold {fold}, Acc on: {acc_on[-1]}, Acc off: {acc_off[-1]}, Acc total: {acc_total[-1]}\")\n",
    "\n",
    "print(f\"Total, Acc on: {np.average(acc_on)}, Acc off: {np.average(acc_off)}, Acc total: {np.average(acc_total)}\")"
   ]
  }
 ]
}